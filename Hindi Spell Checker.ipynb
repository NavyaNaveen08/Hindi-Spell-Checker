{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68486f14-a451-4a2d-af88-7ee90d5726cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spellchecking Accuracy using Levenshtein Distance: 86.00%\n",
      "Accuracy with 50 words: 88.00%\n",
      "Accuracy with 100 words: 83.00%\n",
      "Accuracy with 200 words: 80.00%\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.metrics import edit_distance\n",
    "\n",
    "file_paths = [r\"D:\\tourism.hi.txt\", r\"D:\\second_dataset.hi.txt\", r\"D:\\third_dataset.hi.txt\"]\n",
    "all_words = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    words = text.split()\n",
    "    all_words.extend(words)\n",
    "\n",
    "num_parts = 3\n",
    "split_datasets = [all_words[i::num_parts] for i in range(num_parts)]\n",
    "\n",
    "def generate_ngrams(words, n):\n",
    "    return [tuple(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "\n",
    "bigram_counts = Counter(generate_ngrams(all_words, 2))\n",
    "trigram_counts = Counter(generate_ngrams(all_words, 3))\n",
    "fourgram_counts = Counter(generate_ngrams(all_words, 4))\n",
    "\n",
    "unigram_counts = Counter(all_words)\n",
    "total_unigrams = sum(unigram_counts.values())\n",
    "\n",
    "def calculate_probabilities(ngram_counts, lower_order_counts):\n",
    "    probabilities = {}\n",
    "    for ngram, count in ngram_counts.items():\n",
    "        prefix = ngram[:-1]\n",
    "        prefix_count = lower_order_counts.get(prefix, total_unigrams)\n",
    "        probabilities[ngram] = count / prefix_count\n",
    "    return probabilities\n",
    "\n",
    "bigram_probs = calculate_probabilities(bigram_counts, unigram_counts)\n",
    "trigram_probs = calculate_probabilities(trigram_counts, bigram_counts)\n",
    "fourgram_probs = calculate_probabilities(fourgram_counts, trigram_counts)\n",
    "\n",
    "def introduce_typos(word):\n",
    "    if len(word) > 3:\n",
    "        typo_type = random.choice([\"replace\", \"swap\", \"delete\", \"insert\"])\n",
    "        pos = random.randint(1, len(word) - 2)\n",
    "        \n",
    "        if typo_type == \"replace\":\n",
    "            return word[:pos] + random.choice(\"अआइईउऊएऐओऔकखगघङचछजझटठडढणतथदधनपफबभमयरलवशषसह\") + word[pos+1:]\n",
    "        elif typo_type == \"swap\" and len(word) > 4:\n",
    "            return word[:pos-1] + word[pos] + word[pos-1] + word[pos+1:]\n",
    "        elif typo_type == \"delete\":\n",
    "            return word[:pos] + word[pos+1:]\n",
    "        elif typo_type == \"insert\":\n",
    "            return word[:pos] + random.choice(\"अआइईउऊ\") + word[pos:]\n",
    "    return word\n",
    "\n",
    "def correct_spelling_levenshtein(word, word_list):\n",
    "    subset_words = random.sample(word_list, min(len(word_list), 5000))\n",
    "    return min(subset_words, key=lambda w: edit_distance(word, w))\n",
    "\n",
    "def check_spelling(word):\n",
    "    corrected_word = correct_spelling_levenshtein(word, all_words)\n",
    "    print(f\"Suggested correction: {corrected_word}\")\n",
    "    return corrected_word\n",
    "\n",
    "correct_count = sum(1 for i in range(50) if correct_spelling_levenshtein(introduce_typos(all_words[i]), all_words) == all_words[i])\n",
    "accuracy_levenshtein = correct_count / 50\n",
    "print(f\"Spellchecking Accuracy using Levenshtein Distance: {accuracy_levenshtein:.2%}\")\n",
    "\n",
    "test_sizes = [50, 100, 200]\n",
    "for size in test_sizes:\n",
    "    correct_count = sum(1 for i in range(size) if correct_spelling_levenshtein(introduce_typos(all_words[i]), all_words) == all_words[i])\n",
    "    accuracy = correct_count / size\n",
    "    print(f\"Accuracy with {size} words: {accuracy:.2%}\")\n",
    "\n",
    "def hybrid_correction(word, word_list, ngram_probs, n):\n",
    "    candidates = [w for w in word_list if len(w) == len(word)]\n",
    "    best_word = min(candidates, key=lambda w: (edit_distance(word, w) * 2, -ngram_probs.get(tuple(w[-n:]), 0)))\n",
    "    return best_word\n",
    "\n",
    "correct_count = sum(1 for i in range(50) if hybrid_correction(introduce_typos(all_words[i]), all_words, bigram_probs, 2) == all_words[i])\n",
    "accuracy_hybrid = correct_count / 50\n",
    "print(f\"Hybrid Model Accuracy (Bigram + Edit Distance): {accuracy_hybrid:.2%}\")\n",
    "\n",
    "user_input = input(\"Enter a word to check its spelling: \")\n",
    "check_spelling(user_input)\n",
    "\n",
    "print(f\"The dataset was split into {num_parts} parts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d9ddee-f1d8-4cc4-9291-4e5a69b7fd2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
